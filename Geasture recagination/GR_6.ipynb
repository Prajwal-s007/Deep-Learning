{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def imread(path):\n",
    "    from PIL import Image\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "def imresize(img, size):\n",
    "    from PIL import Image\n",
    "    return np.array(Image.fromarray(img).resize(size)) #documentation: frommarray - Creates an image memory from an object exporting the array interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines()) #readlines() stores each line in a list\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
    "batch_size = 40 #experiment with the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = 30 # No. of frames images\n",
    "# y = 120 # Width of the image\n",
    "# z = 120 # height\n",
    "\n",
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = [x for x in range(0,x)] #create a list of image numbers you want to use for a particular video\n",
    "    #img_idx = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list) #permutes a sequence randomly with the given input\n",
    "        num_batches = len(t)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "\n",
    "                    resized_image = (image*255).astype(np.uint8) #normalizing and converting the images to type uint8 from float32 as imresize() does not accept float32\n",
    "                    resized_image = imresize(resized_image, (y,z)) \n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (resized_image[:,:,0]) \n",
    "                    batch_data[folder,idx,:,:,1] = (resized_image[:,:,1]) \n",
    "                    batch_data[folder,idx,:,:,2] = (resized_image[:,:,2])\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "\n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            batch_size = len(t) - (batch_size*num_batches)\n",
    "            for batch in range(num_batches):\n",
    "                  batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "                  batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "                  for folder in range(batch_size): # iterate over the batch_size\n",
    "                      imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                      for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                          image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                          \n",
    "                          #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                          #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                          \n",
    "                          resized_image = (image*255).astype(np.uint8)\n",
    "                          resized_image = imresize(resized_image, (y,z)) \n",
    "                          \n",
    "                          batch_data[folder,idx,:,:,0] = (resized_image[:,:,0])\n",
    "                          batch_data[folder,idx,:,:,1] = (resized_image[:,:,1])\n",
    "                          batch_data[folder,idx,:,:,2] = (resized_image[:,:,2])\n",
    "                        \n",
    "                      batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "                  yield batch_data, batch_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 20\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = 'Project_data/train'\n",
    "val_path = 'Project_data/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 20 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 0\n",
    "\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam.\n",
    "\n",
    "\n",
    "Inputs: \n",
    "x = 15\n",
    "y = 100\n",
    "z = 100\n",
    "\n",
    "batch_size = 30\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 15 #passing only 15 inputs\n",
    "y = 100 #image height\n",
    "z = 100 #image width\n",
    "\n",
    "num_epochs = 15\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, GRU,Dropout, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#write your model here\n",
    "Input_shape = (15, 100, 100, 3) #15 training images of size (100, 100) with 3 channels\n",
    "\n",
    "model = Sequential()\n",
    "#first layer\n",
    "model.add(Conv3D(16, (3,3,3), padding='same', input_shape = Input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D((2,2,2), padding = \"same\"))\n",
    "\n",
    "#2nd layer\n",
    "model.add(Conv3D(32, (3, 3,3), padding = \"same\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D((2,2,2), padding = \"same\"))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "#3rd layer\n",
    "model.add(Conv3D(64, (3, 3,3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D((2,2,2), padding = \"same\"))\n",
    "\n",
    "#4th layer\n",
    "model.add(Conv3D(128, (3, 3,3), padding = \"same\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D((2,2,2), padding = \"same\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 15, 100, 100, 16)  1312      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 15, 100, 100, 16)  0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 15, 100, 100, 16)  64       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 8, 50, 50, 16)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 8, 50, 50, 32)     13856     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 8, 50, 50, 32)     0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 8, 50, 50, 32)    128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 4, 25, 25, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 4, 25, 25, 64)     55360     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 4, 25, 25, 64)     0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, 25, 25, 64)    256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 2, 13, 13, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_3 (Conv3D)           (None, 2, 13, 13, 128)    221312    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 2, 13, 13, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 2, 13, 13, 128)   512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_3 (MaxPooling  (None, 1, 7, 7, 128)     0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1605888   \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,933,765\n",
      "Trainable params: 1,932,517\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = tf.keras.optimizers.Adam(learning_rate = 0.001) #using adam optimizer with a very low learning rate\n",
    "model.compile(optimizer = optimiser, loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_0' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/' #creating the model name with the current time stamp\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name) #creating the path if it does not already exist\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_loss', verbose = 1, save_best_only = False, save_weights_only = False, mode = 'auto', save_freq = 'epoch') #monitor is used to check specific metrics (val_loss in this case); \n",
    "#verbose displays messages; save_best_only will save only the best possible model out all\n",
    "#save_weights_only: if true, only the weights will be saved.\n",
    "#mode: as per documentation: In auto mode, the mode is set to max if the quantities monitored are 'acc' or start with 'fmeasure' and are set to min for the rest of the quantities.\n",
    "#save_freq: when using 'epoch', the model is saved after each epoch\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 2, cooldown = 1, verbose = 1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/train ; batch size = 30\n",
      "Epoch 1/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.6057 - categorical_accuracy: 0.4103 Source path =  Project_data/val ; batch size = 30\n",
      "\n",
      "Epoch 1: saving model to model_init_0_2022-07-1206_46_11.972365/model-00001-1.60572-0.41026-56.77660-0.22000.h5\n",
      "23/23 [==============================] - 320s 14s/step - loss: 1.6057 - categorical_accuracy: 0.4103 - val_loss: 56.7766 - val_categorical_accuracy: 0.2200 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.8508 - categorical_accuracy: 0.3913\n",
      "Epoch 2: saving model to model_init_0_2022-07-1206_46_11.972365/model-00002-1.85084-0.39130-14.66368-0.30000.h5\n",
      "23/23 [==============================] - 37s 2s/step - loss: 1.8508 - categorical_accuracy: 0.3913 - val_loss: 14.6637 - val_categorical_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 2.1931 - categorical_accuracy: 0.2029\n",
      "Epoch 3: saving model to model_init_0_2022-07-1206_46_11.972365/model-00003-2.19309-0.20290-10.35314-0.22500.h5\n",
      "23/23 [==============================] - 37s 2s/step - loss: 2.1931 - categorical_accuracy: 0.2029 - val_loss: 10.3531 - val_categorical_accuracy: 0.2250 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 2.1639 - categorical_accuracy: 0.2029\n",
      "Epoch 4: saving model to model_init_0_2022-07-1206_46_11.972365/model-00004-2.16388-0.20290-4.71725-0.30000.h5\n",
      "23/23 [==============================] - 37s 2s/step - loss: 2.1639 - categorical_accuracy: 0.2029 - val_loss: 4.7172 - val_categorical_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.9414 - categorical_accuracy: 0.1739\n",
      "Epoch 5: saving model to model_init_0_2022-07-1206_46_11.972365/model-00005-1.94137-0.17391-6.50321-0.12500.h5\n",
      "23/23 [==============================] - 37s 2s/step - loss: 1.9414 - categorical_accuracy: 0.1739 - val_loss: 6.5032 - val_categorical_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.8018 - categorical_accuracy: 0.3333\n",
      "Epoch 6: saving model to model_init_0_2022-07-1206_46_11.972365/model-00006-1.80179-0.33333-3.36889-0.30000.h5\n",
      "23/23 [==============================] - 37s 2s/step - loss: 1.8018 - categorical_accuracy: 0.3333 - val_loss: 3.3689 - val_categorical_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.8793 - categorical_accuracy: 0.2319\n",
      "Epoch 7: saving model to model_init_0_2022-07-1206_46_11.972365/model-00007-1.87926-0.23188-1.91047-0.27500.h5\n",
      "23/23 [==============================] - 36s 2s/step - loss: 1.8793 - categorical_accuracy: 0.2319 - val_loss: 1.9105 - val_categorical_accuracy: 0.2750 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.6492 - categorical_accuracy: 0.3043\n",
      "Epoch 8: saving model to model_init_0_2022-07-1206_46_11.972365/model-00008-1.64921-0.30435-2.87938-0.22500.h5\n",
      "23/23 [==============================] - 37s 2s/step - loss: 1.6492 - categorical_accuracy: 0.3043 - val_loss: 2.8794 - val_categorical_accuracy: 0.2250 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.6406 - categorical_accuracy: 0.2319\n",
      "Epoch 9: saving model to model_init_0_2022-07-1206_46_11.972365/model-00009-1.64065-0.23188-2.49155-0.52500.h5\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "23/23 [==============================] - 37s 2s/step - loss: 1.6406 - categorical_accuracy: 0.2319 - val_loss: 2.4916 - val_categorical_accuracy: 0.5250 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.6696 - categorical_accuracy: 0.3913\n",
      "Epoch 10: saving model to model_init_0_2022-07-1206_46_11.972365/model-00010-1.66964-0.39130-2.04591-0.35000.h5\n",
      "23/23 [==============================] - 36s 2s/step - loss: 1.6696 - categorical_accuracy: 0.3913 - val_loss: 2.0459 - val_categorical_accuracy: 0.3500 - lr: 5.0000e-04\n",
      "Epoch 11/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.9124 - categorical_accuracy: 0.2754\n",
      "Epoch 11: saving model to model_init_0_2022-07-1206_46_11.972365/model-00011-1.91235-0.27536-3.28546-0.12500.h5\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "23/23 [==============================] - 36s 2s/step - loss: 1.9124 - categorical_accuracy: 0.2754 - val_loss: 3.2855 - val_categorical_accuracy: 0.1250 - lr: 5.0000e-04\n",
      "Epoch 12/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.8988 - categorical_accuracy: 0.2899\n",
      "Epoch 12: saving model to model_init_0_2022-07-1206_46_11.972365/model-00012-1.89880-0.28986-2.55089-0.25000.h5\n",
      "23/23 [==============================] - 36s 2s/step - loss: 1.8988 - categorical_accuracy: 0.2899 - val_loss: 2.5509 - val_categorical_accuracy: 0.2500 - lr: 2.5000e-04\n",
      "Epoch 13/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.8054 - categorical_accuracy: 0.3043\n",
      "Epoch 13: saving model to model_init_0_2022-07-1206_46_11.972365/model-00013-1.80537-0.30435-1.79003-0.22500.h5\n",
      "23/23 [==============================] - 36s 2s/step - loss: 1.8054 - categorical_accuracy: 0.3043 - val_loss: 1.7900 - val_categorical_accuracy: 0.2250 - lr: 2.5000e-04\n",
      "Epoch 14/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.7128 - categorical_accuracy: 0.3768\n",
      "Epoch 14: saving model to model_init_0_2022-07-1206_46_11.972365/model-00014-1.71276-0.37681-1.69276-0.32500.h5\n",
      "23/23 [==============================] - 37s 2s/step - loss: 1.7128 - categorical_accuracy: 0.3768 - val_loss: 1.6928 - val_categorical_accuracy: 0.3250 - lr: 2.5000e-04\n",
      "Epoch 15/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.7593 - categorical_accuracy: 0.2899\n",
      "Epoch 15: saving model to model_init_0_2022-07-1206_46_11.972365/model-00015-1.75933-0.28986-1.51508-0.40000.h5\n",
      "23/23 [==============================] - 37s 2s/step - loss: 1.7593 - categorical_accuracy: 0.2899 - val_loss: 1.5151 - val_categorical_accuracy: 0.4000 - lr: 2.5000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe15c7e8760>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch = steps_per_epoch, epochs = num_epochs, verbose = 1,  #steps_per_epoch: The number of batches to run during each\n",
    "                    callbacks = callbacks_list, validation_data = val_generator, #callback performs various activities at different stages. We have assigned checkpoint and LR. Basically it saves the model and prints the metrics\n",
    "                    validation_steps = validation_steps, class_weight = None, workers = 1, initial_epoch = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs: \n",
    "\n",
    "Changing the number of inputs\n",
    "\n",
    "x = 30\n",
    "y = 100\n",
    "z = 100\n",
    "\n",
    "batch_size = 30\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 30\n",
    "y = 100\n",
    "z = 100\n",
    "\n",
    "num_epochs = 15\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_shape = (30, 100, 100, 3)\n",
    "\n",
    "model_1 = Sequential()\n",
    "#first layer\n",
    "model_1.add(Conv3D(16, (3,3,3), padding='same', input_shape = Input_shape))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "#2nd layer\n",
    "model_1.add(Conv3D(32, (3, 3,3), padding = \"same\"))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "#3rd layer\n",
    "model_1.add(Conv3D(64, (3, 3,3), padding='same'))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "#4th layer\n",
    "model_1.add(Conv3D(128, (3, 3,3), padding = \"same\"))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(256))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Dropout(0.25))\n",
    "\n",
    "model_1.add(Dense(128))\n",
    "model_1.add(Activation(\"relu\"))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Dropout(0.25))\n",
    "\n",
    "model_1.add(Dense(5))\n",
    "model_1.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_4 (Conv3D)           (None, 30, 100, 100, 16)  1312      \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 30, 100, 100, 16)  0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 30, 100, 100, 16)  64       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_4 (MaxPooling  (None, 15, 50, 50, 16)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_5 (Conv3D)           (None, 15, 50, 50, 32)    13856     \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 15, 50, 50, 32)    0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 15, 50, 50, 32)   128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_5 (MaxPooling  (None, 8, 25, 25, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_6 (Conv3D)           (None, 8, 25, 25, 64)     55360     \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 8, 25, 25, 64)     0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 8, 25, 25, 64)    256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_6 (MaxPooling  (None, 4, 13, 13, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_7 (Conv3D)           (None, 4, 13, 13, 128)    221312    \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 4, 13, 13, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 4, 13, 13, 128)   512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_7 (MaxPooling  (None, 2, 7, 7, 128)     0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               3211520   \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,539,397\n",
      "Trainable params: 3,538,149\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = tf.keras.optimizers.Adam(learning_rate = 0.001) #write your optimizer\n",
    "model_1.compile(optimizer=optimiser, loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_1' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_loss', verbose = 1, save_best_only = False, save_weights_only = False, mode = 'auto', save_freq = 'epoch')\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 2, cooldown = 1, verbose = 1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/train ; batch size = 30\n",
      "Epoch 1/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.4840 - categorical_accuracy: 0.4646 Source path =  Project_data/val ; batch size = 30\n",
      "\n",
      "Epoch 1: saving model to model_init_1_2022-07-1206_46_11.972365/model-00001-1.48401-0.46456-56.26824-0.23000.h5\n",
      "23/23 [==============================] - 638s 28s/step - loss: 1.4840 - categorical_accuracy: 0.4646 - val_loss: 56.2682 - val_categorical_accuracy: 0.2300 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.7441 - categorical_accuracy: 0.4203\n",
      "Epoch 2: saving model to model_init_1_2022-07-1206_46_11.972365/model-00002-1.74407-0.42029-27.81855-0.10000.h5\n",
      "23/23 [==============================] - 75s 3s/step - loss: 1.7441 - categorical_accuracy: 0.4203 - val_loss: 27.8185 - val_categorical_accuracy: 0.1000 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.8536 - categorical_accuracy: 0.3478\n",
      "Epoch 3: saving model to model_init_1_2022-07-1206_46_11.972365/model-00003-1.85358-0.34783-9.83829-0.27500.h5\n",
      "23/23 [==============================] - 74s 3s/step - loss: 1.8536 - categorical_accuracy: 0.3478 - val_loss: 9.8383 - val_categorical_accuracy: 0.2750 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.8300 - categorical_accuracy: 0.3333\n",
      "Epoch 4: saving model to model_init_1_2022-07-1206_46_11.972365/model-00004-1.82998-0.33333-3.12187-0.17500.h5\n",
      "23/23 [==============================] - 75s 3s/step - loss: 1.8300 - categorical_accuracy: 0.3333 - val_loss: 3.1219 - val_categorical_accuracy: 0.1750 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.9141 - categorical_accuracy: 0.3333\n",
      "Epoch 5: saving model to model_init_1_2022-07-1206_46_11.972365/model-00005-1.91412-0.33333-7.79581-0.22500.h5\n",
      "23/23 [==============================] - 74s 3s/step - loss: 1.9141 - categorical_accuracy: 0.3333 - val_loss: 7.7958 - val_categorical_accuracy: 0.2250 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.9626 - categorical_accuracy: 0.3188\n",
      "Epoch 6: saving model to model_init_1_2022-07-1206_46_11.972365/model-00006-1.96263-0.31884-3.19290-0.32500.h5\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "23/23 [==============================] - 74s 3s/step - loss: 1.9626 - categorical_accuracy: 0.3188 - val_loss: 3.1929 - val_categorical_accuracy: 0.3250 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.6199 - categorical_accuracy: 0.3768\n",
      "Epoch 7: saving model to model_init_1_2022-07-1206_46_11.972365/model-00007-1.61988-0.37681-2.37656-0.32500.h5\n",
      "23/23 [==============================] - 74s 3s/step - loss: 1.6199 - categorical_accuracy: 0.3768 - val_loss: 2.3766 - val_categorical_accuracy: 0.3250 - lr: 5.0000e-04\n",
      "Epoch 8/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5736 - categorical_accuracy: 0.3913\n",
      "Epoch 8: saving model to model_init_1_2022-07-1206_46_11.972365/model-00008-1.57361-0.39130-1.53679-0.42500.h5\n",
      "23/23 [==============================] - 74s 3s/step - loss: 1.5736 - categorical_accuracy: 0.3913 - val_loss: 1.5368 - val_categorical_accuracy: 0.4250 - lr: 5.0000e-04\n",
      "Epoch 9/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.9653 - categorical_accuracy: 0.2319\n",
      "Epoch 9: saving model to model_init_1_2022-07-1206_46_11.972365/model-00009-1.96525-0.23188-2.13510-0.22500.h5\n",
      "23/23 [==============================] - 74s 3s/step - loss: 1.9653 - categorical_accuracy: 0.2319 - val_loss: 2.1351 - val_categorical_accuracy: 0.2250 - lr: 5.0000e-04\n",
      "Epoch 10/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.7445 - categorical_accuracy: 0.3623\n",
      "Epoch 10: saving model to model_init_1_2022-07-1206_46_11.972365/model-00010-1.74449-0.36232-2.12046-0.32500.h5\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "23/23 [==============================] - 75s 3s/step - loss: 1.7445 - categorical_accuracy: 0.3623 - val_loss: 2.1205 - val_categorical_accuracy: 0.3250 - lr: 5.0000e-04\n",
      "Epoch 11/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5665 - categorical_accuracy: 0.3333\n",
      "Epoch 11: saving model to model_init_1_2022-07-1206_46_11.972365/model-00011-1.56650-0.33333-1.80548-0.42500.h5\n",
      "23/23 [==============================] - 75s 3s/step - loss: 1.5665 - categorical_accuracy: 0.3333 - val_loss: 1.8055 - val_categorical_accuracy: 0.4250 - lr: 2.5000e-04\n",
      "Epoch 12/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.3996 - categorical_accuracy: 0.4928\n",
      "Epoch 12: saving model to model_init_1_2022-07-1206_46_11.972365/model-00012-1.39956-0.49275-1.88239-0.37500.h5\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "23/23 [==============================] - 74s 3s/step - loss: 1.3996 - categorical_accuracy: 0.4928 - val_loss: 1.8824 - val_categorical_accuracy: 0.3750 - lr: 2.5000e-04\n",
      "Epoch 13/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 2.0274 - categorical_accuracy: 0.2174\n",
      "Epoch 13: saving model to model_init_1_2022-07-1206_46_11.972365/model-00013-2.02737-0.21739-1.94171-0.30000.h5\n",
      "23/23 [==============================] - 74s 3s/step - loss: 2.0274 - categorical_accuracy: 0.2174 - val_loss: 1.9417 - val_categorical_accuracy: 0.3000 - lr: 1.2500e-04\n",
      "Epoch 14/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.9154 - categorical_accuracy: 0.2609\n",
      "Epoch 14: saving model to model_init_1_2022-07-1206_46_11.972365/model-00014-1.91544-0.26087-1.85045-0.30000.h5\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "23/23 [==============================] - 75s 3s/step - loss: 1.9154 - categorical_accuracy: 0.2609 - val_loss: 1.8505 - val_categorical_accuracy: 0.3000 - lr: 1.2500e-04\n",
      "Epoch 15/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.6202 - categorical_accuracy: 0.4058\n",
      "Epoch 15: saving model to model_init_1_2022-07-1206_46_11.972365/model-00015-1.62015-0.40580-2.19588-0.32500.h5\n",
      "23/23 [==============================] - 75s 3s/step - loss: 1.6202 - categorical_accuracy: 0.4058 - val_loss: 2.1959 - val_categorical_accuracy: 0.3250 - lr: 6.2500e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe112d719a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(train_generator, steps_per_epoch = steps_per_epoch, epochs = num_epochs, verbose = 1, \n",
    "                    callbacks = callbacks_list, validation_data = val_generator, \n",
    "                    validation_steps = validation_steps, class_weight = None, workers = 1, initial_epoch = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs:\n",
    "x = 30\n",
    "y = 100\n",
    "z = 100\n",
    "\n",
    "Changing batch size and number of epochs\n",
    "\n",
    "\n",
    "batch_size = 45\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 30\n",
    "y = 100\n",
    "z = 100\n",
    "\n",
    "num_epochs = 20\n",
    "batch_size = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_shape = (30, 100, 100, 3)\n",
    "\n",
    "model_2 = Sequential()\n",
    "#first layer\n",
    "model_2.add(Conv3D(16, (3,3,3), padding='same', input_shape = Input_shape))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "#2nd layer\n",
    "model_2.add(Conv3D(32, (3, 3,3), padding = \"same\"))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "#3rd layer\n",
    "model_2.add(Conv3D(64, (3, 3,3), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "#4th layer\n",
    "model_2.add(Conv3D(128, (3, 3,3), padding = \"same\"))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(256))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "model_2.add(Dense(128))\n",
    "model_2.add(Activation(\"relu\"))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "model_2.add(Dense(5))\n",
    "model_2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_8 (Conv3D)           (None, 30, 100, 100, 16)  1312      \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 30, 100, 100, 16)  0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 30, 100, 100, 16)  64       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_8 (MaxPooling  (None, 15, 50, 50, 16)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_9 (Conv3D)           (None, 15, 50, 50, 32)    13856     \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 15, 50, 50, 32)    0         \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 15, 50, 50, 32)   128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_9 (MaxPooling  (None, 8, 25, 25, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_10 (Conv3D)          (None, 8, 25, 25, 64)     55360     \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 8, 25, 25, 64)     0         \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 8, 25, 25, 64)    256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_10 (MaxPoolin  (None, 4, 13, 13, 64)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_11 (Conv3D)          (None, 4, 13, 13, 128)    221312    \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 4, 13, 13, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 4, 13, 13, 128)   512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_11 (MaxPoolin  (None, 2, 7, 7, 128)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               3211520   \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,539,397\n",
      "Trainable params: 3,538,149\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = tf.keras.optimizers.Adam(learning_rate = 0.001) #write your optimizer\n",
    "model_2.compile(optimizer = optimiser, loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "print (model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_2' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_loss', verbose = 1, save_best_only = False, save_weights_only = False, mode = 'auto', save_freq = 'epoch')\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 2, cooldown = 1, verbose = 1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/train ; batch size = 45\n",
      "Epoch 1/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.4702 - categorical_accuracy: 0.4419 Source path =  Project_data/val ; batch size = 45\n",
      "\n",
      "Epoch 1: saving model to model_init_2_2022-07-1206_46_11.972365/model-00001-1.47017-0.44193-48.60880-0.23000.h5\n",
      "15/15 [==============================] - 635s 42s/step - loss: 1.4702 - categorical_accuracy: 0.4419 - val_loss: 48.6088 - val_categorical_accuracy: 0.2300 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.8781 - categorical_accuracy: 0.6667 \n",
      "Epoch 2: saving model to model_init_2_2022-07-1206_46_11.972365/model-00002-0.87814-0.66667-26.96347-0.16667.h5\n",
      "15/15 [==============================] - 462s 31s/step - loss: 0.8781 - categorical_accuracy: 0.6667 - val_loss: 26.9635 - val_categorical_accuracy: 0.1667 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.7067 - categorical_accuracy: 0.7253 \n",
      "Epoch 3: saving model to model_init_2_2022-07-1206_46_11.972365/model-00003-0.70674-0.72525-20.74389-0.26667.h5\n",
      "15/15 [==============================] - 464s 31s/step - loss: 0.7067 - categorical_accuracy: 0.7253 - val_loss: 20.7439 - val_categorical_accuracy: 0.2667 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.9246 - categorical_accuracy: 0.6370\n",
      "Epoch 4: saving model to model_init_2_2022-07-1206_46_11.972365/model-00004-0.92458-0.63704-54.64492-0.26667.h5\n",
      "15/15 [==============================] - 133s 7s/step - loss: 0.9246 - categorical_accuracy: 0.6370 - val_loss: 54.6449 - val_categorical_accuracy: 0.2667 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 2.1181 - categorical_accuracy: 0.2444\n",
      "Epoch 5: saving model to model_init_2_2022-07-1206_46_11.972365/model-00005-2.11806-0.24444-272.07968-0.26667.h5\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "15/15 [==============================] - 49s 3s/step - loss: 2.1181 - categorical_accuracy: 0.2444 - val_loss: 272.0797 - val_categorical_accuracy: 0.2667 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 2.2554 - categorical_accuracy: 0.2889\n",
      "Epoch 6: saving model to model_init_2_2022-07-1206_46_11.972365/model-00006-2.25538-0.28889-179.16188-0.23333.h5\n",
      "15/15 [==============================] - 50s 3s/step - loss: 2.2554 - categorical_accuracy: 0.2889 - val_loss: 179.1619 - val_categorical_accuracy: 0.2333 - lr: 5.0000e-04\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 2.0925 - categorical_accuracy: 0.2889\n",
      "Epoch 7: saving model to model_init_2_2022-07-1206_46_11.972365/model-00007-2.09255-0.28889-53.72857-0.26667.h5\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "15/15 [==============================] - 50s 3s/step - loss: 2.0925 - categorical_accuracy: 0.2889 - val_loss: 53.7286 - val_categorical_accuracy: 0.2667 - lr: 5.0000e-04\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.8791 - categorical_accuracy: 0.2222\n",
      "Epoch 8: saving model to model_init_2_2022-07-1206_46_11.972365/model-00008-1.87907-0.22222-29.87359-0.23333.h5\n",
      "15/15 [==============================] - 50s 3s/step - loss: 1.8791 - categorical_accuracy: 0.2222 - val_loss: 29.8736 - val_categorical_accuracy: 0.2333 - lr: 2.5000e-04\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.6839 - categorical_accuracy: 0.2222\n",
      "Epoch 9: saving model to model_init_2_2022-07-1206_46_11.972365/model-00009-1.68388-0.22222-21.70046-0.26667.h5\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.6839 - categorical_accuracy: 0.2222 - val_loss: 21.7005 - val_categorical_accuracy: 0.2667 - lr: 2.5000e-04\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 2.1347 - categorical_accuracy: 0.2000\n",
      "Epoch 10: saving model to model_init_2_2022-07-1206_46_11.972365/model-00010-2.13472-0.20000-16.22602-0.20000.h5\n",
      "15/15 [==============================] - 50s 3s/step - loss: 2.1347 - categorical_accuracy: 0.2000 - val_loss: 16.2260 - val_categorical_accuracy: 0.2000 - lr: 1.2500e-04\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.5054 - categorical_accuracy: 0.4222\n",
      "Epoch 11: saving model to model_init_2_2022-07-1206_46_11.972365/model-00011-1.50544-0.42222-8.68277-0.33333.h5\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.5054 - categorical_accuracy: 0.4222 - val_loss: 8.6828 - val_categorical_accuracy: 0.3333 - lr: 1.2500e-04\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.5670 - categorical_accuracy: 0.4000\n",
      "Epoch 12: saving model to model_init_2_2022-07-1206_46_11.972365/model-00012-1.56698-0.40000-7.26261-0.30000.h5\n",
      "15/15 [==============================] - 50s 3s/step - loss: 1.5670 - categorical_accuracy: 0.4000 - val_loss: 7.2626 - val_categorical_accuracy: 0.3000 - lr: 1.2500e-04\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.8689 - categorical_accuracy: 0.2667\n",
      "Epoch 13: saving model to model_init_2_2022-07-1206_46_11.972365/model-00013-1.86894-0.26667-4.31099-0.36667.h5\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.8689 - categorical_accuracy: 0.2667 - val_loss: 4.3110 - val_categorical_accuracy: 0.3667 - lr: 1.2500e-04\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.8251 - categorical_accuracy: 0.3111\n",
      "Epoch 14: saving model to model_init_2_2022-07-1206_46_11.972365/model-00014-1.82514-0.31111-3.89078-0.33333.h5\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.8251 - categorical_accuracy: 0.3111 - val_loss: 3.8908 - val_categorical_accuracy: 0.3333 - lr: 1.2500e-04\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.9328 - categorical_accuracy: 0.2444\n",
      "Epoch 15: saving model to model_init_2_2022-07-1206_46_11.972365/model-00015-1.93280-0.24444-3.08305-0.36667.h5\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.9328 - categorical_accuracy: 0.2444 - val_loss: 3.0831 - val_categorical_accuracy: 0.3667 - lr: 1.2500e-04\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.7321 - categorical_accuracy: 0.3111\n",
      "Epoch 16: saving model to model_init_2_2022-07-1206_46_11.972365/model-00016-1.73214-0.31111-2.62782-0.26667.h5\n",
      "15/15 [==============================] - 50s 3s/step - loss: 1.7321 - categorical_accuracy: 0.3111 - val_loss: 2.6278 - val_categorical_accuracy: 0.2667 - lr: 1.2500e-04\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.8672 - categorical_accuracy: 0.2889\n",
      "Epoch 17: saving model to model_init_2_2022-07-1206_46_11.972365/model-00017-1.86716-0.28889-2.13877-0.43333.h5\n",
      "15/15 [==============================] - 50s 3s/step - loss: 1.8672 - categorical_accuracy: 0.2889 - val_loss: 2.1388 - val_categorical_accuracy: 0.4333 - lr: 1.2500e-04\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.8870 - categorical_accuracy: 0.3556\n",
      "Epoch 18: saving model to model_init_2_2022-07-1206_46_11.972365/model-00018-1.88698-0.35556-1.80413-0.36667.h5\n",
      "15/15 [==============================] - 50s 3s/step - loss: 1.8870 - categorical_accuracy: 0.3556 - val_loss: 1.8041 - val_categorical_accuracy: 0.3667 - lr: 1.2500e-04\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.9055 - categorical_accuracy: 0.2667\n",
      "Epoch 19: saving model to model_init_2_2022-07-1206_46_11.972365/model-00019-1.90545-0.26667-2.02459-0.36667.h5\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.9055 - categorical_accuracy: 0.2667 - val_loss: 2.0246 - val_categorical_accuracy: 0.3667 - lr: 1.2500e-04\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.6342 - categorical_accuracy: 0.2667\n",
      "Epoch 20: saving model to model_init_2_2022-07-1206_46_11.972365/model-00020-1.63419-0.26667-1.28003-0.40000.h5\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.6342 - categorical_accuracy: 0.2667 - val_loss: 1.2800 - val_categorical_accuracy: 0.4000 - lr: 1.2500e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe15c738df0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(train_generator, steps_per_epoch = steps_per_epoch, epochs = num_epochs, verbose = 1, \n",
    "                    callbacks = callbacks_list, validation_data = val_generator, \n",
    "                    validation_steps = validation_steps, class_weight = None, workers = 1, initial_epoch = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs:\n",
    "x = 30\n",
    "y = 100\n",
    "z = 100\n",
    "\n",
    "Changing batch size and number of epochs:\n",
    "\n",
    "batch_size = 45\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 30\n",
    "y = 100\n",
    "z = 100\n",
    "\n",
    "num_epochs = 25\n",
    "batch_size = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_shape = (30, 100, 100, 3)\n",
    "\n",
    "model_3 = Sequential()\n",
    "#first layer\n",
    "model_3.add(Conv3D(16, (3,3,3), padding = 'same', input_shape = Input_shape))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "#2nd layer\n",
    "model_3.add(Conv3D(32, (3, 3,3), padding = \"same\"))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "#3rd layer\n",
    "model_3.add(Conv3D(64, (3, 3,3), padding='same'))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "#4th layer\n",
    "model_3.add(Conv3D(128, (3, 3,3), padding = \"same\"))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(256))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Dropout(0.25))\n",
    "\n",
    "model_3.add(Dense(128))\n",
    "model_3.add(Activation(\"relu\"))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Dropout(0.25))\n",
    "\n",
    "model_3.add(Dense(5))\n",
    "model_3.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_12 (Conv3D)          (None, 30, 100, 100, 16)  1312      \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 30, 100, 100, 16)  0         \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 30, 100, 100, 16)  64       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_12 (MaxPoolin  (None, 15, 50, 50, 16)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_13 (Conv3D)          (None, 15, 50, 50, 32)    13856     \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 15, 50, 50, 32)    0         \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 15, 50, 50, 32)   128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_13 (MaxPoolin  (None, 8, 25, 25, 32)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_14 (Conv3D)          (None, 8, 25, 25, 64)     55360     \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 8, 25, 25, 64)     0         \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 8, 25, 25, 64)    256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_14 (MaxPoolin  (None, 4, 13, 13, 64)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_15 (Conv3D)          (None, 4, 13, 13, 128)    221312    \n",
      "                                                                 \n",
      " activation_24 (Activation)  (None, 4, 13, 13, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 4, 13, 13, 128)   512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_15 (MaxPoolin  (None, 2, 7, 7, 128)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               3211520   \n",
      "                                                                 \n",
      " activation_25 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5)                 645       \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,539,397\n",
      "Trainable params: 3,538,149\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = tf.keras.optimizers.Adam(learning_rate = 0.001) #write your optimizer\n",
    "model_3.compile(optimizer = optimiser, loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "print(model_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_3' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_loss', verbose = 1, save_best_only = False, save_weights_only = False, mode = 'auto', save_freq = 'epoch')\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 2, cooldown = 1, verbose = 1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/train ; batch size = 45\n",
      "Epoch 1/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.4570 - categorical_accuracy: 0.4419 Source path =  Project_data/val ; batch size = 45\n",
      "\n",
      "Epoch 1: saving model to model_init_3_2022-07-1206_46_11.972365/model-00001-1.45702-0.44193-58.34675-0.21000.h5\n",
      "15/15 [==============================] - 637s 42s/step - loss: 1.4570 - categorical_accuracy: 0.4419 - val_loss: 58.3468 - val_categorical_accuracy: 0.2100 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.9686 - categorical_accuracy: 0.6141 \n",
      "Epoch 2: saving model to model_init_3_2022-07-1206_46_11.972365/model-00002-0.96857-0.61414-66.41541-0.16667.h5\n",
      "15/15 [==============================] - 467s 31s/step - loss: 0.9686 - categorical_accuracy: 0.6141 - val_loss: 66.4154 - val_categorical_accuracy: 0.1667 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.7718 - categorical_accuracy: 0.7172 \n",
      "Epoch 3: saving model to model_init_3_2022-07-1206_46_11.972365/model-00003-0.77184-0.71717-19.99282-0.33333.h5\n",
      "15/15 [==============================] - 467s 31s/step - loss: 0.7718 - categorical_accuracy: 0.7172 - val_loss: 19.9928 - val_categorical_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.9932 - categorical_accuracy: 0.6222\n",
      "Epoch 4: saving model to model_init_3_2022-07-1206_46_11.972365/model-00004-0.99319-0.62222-30.37951-0.30000.h5\n",
      "15/15 [==============================] - 132s 7s/step - loss: 0.9932 - categorical_accuracy: 0.6222 - val_loss: 30.3795 - val_categorical_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.7960 - categorical_accuracy: 0.3111\n",
      "Epoch 5: saving model to model_init_3_2022-07-1206_46_11.972365/model-00005-1.79597-0.31111-118.52847-0.30000.h5\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.7960 - categorical_accuracy: 0.3111 - val_loss: 118.5285 - val_categorical_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.8477 - categorical_accuracy: 0.3111\n",
      "Epoch 6: saving model to model_init_3_2022-07-1206_46_11.972365/model-00006-1.84766-0.31111-54.38271-0.16667.h5\n",
      "15/15 [==============================] - 50s 3s/step - loss: 1.8477 - categorical_accuracy: 0.3111 - val_loss: 54.3827 - val_categorical_accuracy: 0.1667 - lr: 5.0000e-04\n",
      "Epoch 7/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.8047 - categorical_accuracy: 0.4000\n",
      "Epoch 7: saving model to model_init_3_2022-07-1206_46_11.972365/model-00007-1.80465-0.40000-27.14394-0.16667.h5\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "15/15 [==============================] - 50s 3s/step - loss: 1.8047 - categorical_accuracy: 0.4000 - val_loss: 27.1439 - val_categorical_accuracy: 0.1667 - lr: 5.0000e-04\n",
      "Epoch 8/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.9901 - categorical_accuracy: 0.2667\n",
      "Epoch 8: saving model to model_init_3_2022-07-1206_46_11.972365/model-00008-1.99010-0.26667-14.62499-0.30000.h5\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.9901 - categorical_accuracy: 0.2667 - val_loss: 14.6250 - val_categorical_accuracy: 0.3000 - lr: 2.5000e-04\n",
      "Epoch 9/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.7985 - categorical_accuracy: 0.3556\n",
      "Epoch 9: saving model to model_init_3_2022-07-1206_46_11.972365/model-00009-1.79855-0.35556-20.21158-0.13333.h5\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.7985 - categorical_accuracy: 0.3556 - val_loss: 20.2116 - val_categorical_accuracy: 0.1333 - lr: 2.5000e-04\n",
      "Epoch 10/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.8265 - categorical_accuracy: 0.2889\n",
      "Epoch 10: saving model to model_init_3_2022-07-1206_46_11.972365/model-00010-1.82648-0.28889-17.26401-0.16667.h5\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.8265 - categorical_accuracy: 0.2889 - val_loss: 17.2640 - val_categorical_accuracy: 0.1667 - lr: 2.5000e-04\n",
      "Epoch 11/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.4084 - categorical_accuracy: 0.3556\n",
      "Epoch 11: saving model to model_init_3_2022-07-1206_46_11.972365/model-00011-1.40843-0.35556-9.38660-0.33333.h5\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.4084 - categorical_accuracy: 0.3556 - val_loss: 9.3866 - val_categorical_accuracy: 0.3333 - lr: 1.2500e-04\n",
      "Epoch 12/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.5862 - categorical_accuracy: 0.2889\n",
      "Epoch 12: saving model to model_init_3_2022-07-1206_46_11.972365/model-00012-1.58617-0.28889-5.43643-0.43333.h5\n",
      "15/15 [==============================] - 50s 3s/step - loss: 1.5862 - categorical_accuracy: 0.2889 - val_loss: 5.4364 - val_categorical_accuracy: 0.4333 - lr: 1.2500e-04\n",
      "Epoch 13/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.8204 - categorical_accuracy: 0.3333\n",
      "Epoch 13: saving model to model_init_3_2022-07-1206_46_11.972365/model-00013-1.82038-0.33333-3.21819-0.56667.h5\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.8204 - categorical_accuracy: 0.3333 - val_loss: 3.2182 - val_categorical_accuracy: 0.5667 - lr: 1.2500e-04\n",
      "Epoch 14/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.9324 - categorical_accuracy: 0.2444\n",
      "Epoch 14: saving model to model_init_3_2022-07-1206_46_11.972365/model-00014-1.93241-0.24444-1.91739-0.50000.h5\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.9324 - categorical_accuracy: 0.2444 - val_loss: 1.9174 - val_categorical_accuracy: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 15/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.9768 - categorical_accuracy: 0.2444\n",
      "Epoch 15: saving model to model_init_3_2022-07-1206_46_11.972365/model-00015-1.97679-0.24444-0.92453-0.80000.h5\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.9768 - categorical_accuracy: 0.2444 - val_loss: 0.9245 - val_categorical_accuracy: 0.8000 - lr: 1.2500e-04\n",
      "Epoch 16/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.6206 - categorical_accuracy: 0.3778\n",
      "Epoch 16: saving model to model_init_3_2022-07-1206_46_11.972365/model-00016-1.62063-0.37778-3.62674-0.33333.h5\n",
      "15/15 [==============================] - 50s 3s/step - loss: 1.6206 - categorical_accuracy: 0.3778 - val_loss: 3.6267 - val_categorical_accuracy: 0.3333 - lr: 1.2500e-04\n",
      "Epoch 17/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.4538 - categorical_accuracy: 0.3778\n",
      "Epoch 17: saving model to model_init_3_2022-07-1206_46_11.972365/model-00017-1.45377-0.37778-2.32038-0.50000.h5\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "15/15 [==============================] - 50s 3s/step - loss: 1.4538 - categorical_accuracy: 0.3778 - val_loss: 2.3204 - val_categorical_accuracy: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 18/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.6525 - categorical_accuracy: 0.3333\n",
      "Epoch 18: saving model to model_init_3_2022-07-1206_46_11.972365/model-00018-1.65245-0.33333-1.22244-0.53333.h5\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.6525 - categorical_accuracy: 0.3333 - val_loss: 1.2224 - val_categorical_accuracy: 0.5333 - lr: 6.2500e-05\n",
      "Epoch 19/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.3709 - categorical_accuracy: 0.4444\n",
      "Epoch 19: saving model to model_init_3_2022-07-1206_46_11.972365/model-00019-1.37092-0.44444-1.46218-0.53333.h5\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "15/15 [==============================] - 50s 3s/step - loss: 1.3709 - categorical_accuracy: 0.4444 - val_loss: 1.4622 - val_categorical_accuracy: 0.5333 - lr: 6.2500e-05\n",
      "Epoch 20/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.5651 - categorical_accuracy: 0.4444\n",
      "Epoch 20: saving model to model_init_3_2022-07-1206_46_11.972365/model-00020-1.56511-0.44444-1.69066-0.50000.h5\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.5651 - categorical_accuracy: 0.4444 - val_loss: 1.6907 - val_categorical_accuracy: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 21/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.5664 - categorical_accuracy: 0.4000\n",
      "Epoch 21: saving model to model_init_3_2022-07-1206_46_11.972365/model-00021-1.56637-0.40000-1.95349-0.46667.h5\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.5664 - categorical_accuracy: 0.4000 - val_loss: 1.9535 - val_categorical_accuracy: 0.4667 - lr: 3.1250e-05\n",
      "Epoch 22/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.6400 - categorical_accuracy: 0.3333\n",
      "Epoch 22: saving model to model_init_3_2022-07-1206_46_11.972365/model-00022-1.63995-0.33333-1.39233-0.46667.h5\n",
      "15/15 [==============================] - 50s 3s/step - loss: 1.6400 - categorical_accuracy: 0.3333 - val_loss: 1.3923 - val_categorical_accuracy: 0.4667 - lr: 1.5625e-05\n",
      "Epoch 23/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.6532 - categorical_accuracy: 0.3778\n",
      "Epoch 23: saving model to model_init_3_2022-07-1206_46_11.972365/model-00023-1.65315-0.37778-0.88707-0.70000.h5\n",
      "15/15 [==============================] - 50s 3s/step - loss: 1.6532 - categorical_accuracy: 0.3778 - val_loss: 0.8871 - val_categorical_accuracy: 0.7000 - lr: 1.5625e-05\n",
      "Epoch 24/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.5876 - categorical_accuracy: 0.3556\n",
      "Epoch 24: saving model to model_init_3_2022-07-1206_46_11.972365/model-00024-1.58757-0.35556-1.74235-0.53333.h5\n",
      "15/15 [==============================] - 49s 3s/step - loss: 1.5876 - categorical_accuracy: 0.3556 - val_loss: 1.7424 - val_categorical_accuracy: 0.5333 - lr: 1.5625e-05\n",
      "Epoch 25/25\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.4999 - categorical_accuracy: 0.4444\n",
      "Epoch 25: saving model to model_init_3_2022-07-1206_46_11.972365/model-00025-1.49993-0.44444-1.97059-0.46667.h5\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "15/15 [==============================] - 50s 3s/step - loss: 1.4999 - categorical_accuracy: 0.4444 - val_loss: 1.9706 - val_categorical_accuracy: 0.4667 - lr: 1.5625e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe112715070>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(train_generator, steps_per_epoch = steps_per_epoch, epochs = num_epochs, verbose = 1, \n",
    "                    callbacks = callbacks_list, validation_data = val_generator, \n",
    "                    validation_steps = validation_steps, class_weight = None, workers = 1, initial_epoch = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs: \n",
    "\n",
    "Changing the image size from (100, 100) to (120, 120)\n",
    "\n",
    "x = 30\n",
    "y = 120\n",
    "z = 120\n",
    "\n",
    "Reducing the number of epochs:\n",
    "batch_size = 40\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 30\n",
    "y = 120\n",
    "z = 120\n",
    "\n",
    "batch_size = 40\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_shape = (30, 120, 120, 3)\n",
    "\n",
    "model_4 = Sequential()\n",
    "#first layer\n",
    "model_4.add(Conv3D(16, (3,3,3), padding='same', input_shape = Input_shape))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "#2nd layer\n",
    "model_4.add(Conv3D(32, (3, 3,3), padding = \"same\"))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "#3rd layer\n",
    "model_4.add(Conv3D(64, (3, 3,3), padding='same'))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "#4th layer\n",
    "model_4.add(Conv3D(128, (3, 3,3), padding = \"same\"))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(256))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Dropout(0.25))\n",
    "\n",
    "model_4.add(Dense(128))\n",
    "model_4.add(Activation(\"relu\"))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Dropout(0.25))\n",
    "\n",
    "model_4.add(Dense(5))\n",
    "model_4.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 30, 120, 120, 16)  1312      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 30, 120, 120, 16)  0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 30, 120, 120, 16)  64       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 15, 60, 60, 16)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 15, 60, 60, 32)    13856     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 15, 60, 60, 32)    0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 15, 60, 60, 32)   128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 8, 30, 30, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 8, 30, 30, 64)     55360     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 8, 30, 30, 64)     0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 30, 30, 64)    256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 4, 15, 15, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_3 (Conv3D)           (None, 4, 15, 15, 128)    221312    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4, 15, 15, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 15, 15, 128)   512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_3 (MaxPooling  (None, 2, 8, 8, 128)     0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               4194560   \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,522,437\n",
      "Trainable params: 4,521,189\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "model_4.compile(optimizer = optimiser, loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "print(model_4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_4' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_loss', verbose = 1, save_best_only = False, save_weights_only = False, mode = 'auto', save_freq = 'epoch')\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 2, cooldown = 1, verbose = 1)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/train ; batch size = 40\n",
      "Epoch 1/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.5644 - categorical_accuracy: 0.4570 Source path =  Project_data/val ; batch size = 40\n",
      "\n",
      "Epoch 1: saving model to model_init_4_2022-07-1209_53_17.910281/model-00001-1.56435-0.45701-43.73214-0.23000.h5\n",
      "17/17 [==============================] - 907s 53s/step - loss: 1.5644 - categorical_accuracy: 0.4570 - val_loss: 43.7321 - val_categorical_accuracy: 0.2300 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0258 - categorical_accuracy: 0.6215 \n",
      "Epoch 2: saving model to model_init_4_2022-07-1209_53_17.910281/model-00002-1.02577-0.62148-15.26606-0.28333.h5\n",
      "17/17 [==============================] - 531s 31s/step - loss: 1.0258 - categorical_accuracy: 0.6215 - val_loss: 15.2661 - val_categorical_accuracy: 0.2833 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9269 - categorical_accuracy: 0.6394 \n",
      "Epoch 3: saving model to model_init_4_2022-07-1209_53_17.910281/model-00003-0.92690-0.63939-8.00950-0.23333.h5\n",
      "17/17 [==============================] - 530s 31s/step - loss: 0.9269 - categorical_accuracy: 0.6394 - val_loss: 8.0095 - val_categorical_accuracy: 0.2333 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8391 - categorical_accuracy: 0.6825 \n",
      "Epoch 4: saving model to model_init_4_2022-07-1209_53_17.910281/model-00004-0.83913-0.68245-8.14006-0.23333.h5\n",
      "17/17 [==============================] - 489s 29s/step - loss: 0.8391 - categorical_accuracy: 0.6825 - val_loss: 8.1401 - val_categorical_accuracy: 0.2333 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7828 - categorical_accuracy: 0.6780 \n",
      "Epoch 5: saving model to model_init_4_2022-07-1209_53_17.910281/model-00005-0.78281-0.67802-4.88895-0.25000.h5\n",
      "17/17 [==============================] - 442s 26s/step - loss: 0.7828 - categorical_accuracy: 0.6780 - val_loss: 4.8890 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7320 - categorical_accuracy: 0.7028 \n",
      "Epoch 6: saving model to model_init_4_2022-07-1209_53_17.910281/model-00006-0.73202-0.70279-2.27888-0.33333.h5\n",
      "17/17 [==============================] - 443s 26s/step - loss: 0.7320 - categorical_accuracy: 0.7028 - val_loss: 2.2789 - val_categorical_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5928 - categorical_accuracy: 0.7523 \n",
      "Epoch 7: saving model to model_init_4_2022-07-1209_53_17.910281/model-00007-0.59284-0.75232-1.68162-0.43333.h5\n",
      "17/17 [==============================] - 442s 26s/step - loss: 0.5928 - categorical_accuracy: 0.7523 - val_loss: 1.6816 - val_categorical_accuracy: 0.4333 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6274 - categorical_accuracy: 0.7593 \n",
      "Epoch 8: saving model to model_init_4_2022-07-1209_53_17.910281/model-00008-0.62742-0.75932-2.74928-0.31667.h5\n",
      "17/17 [==============================] - 404s 24s/step - loss: 0.6274 - categorical_accuracy: 0.7593 - val_loss: 2.7493 - val_categorical_accuracy: 0.3167 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5794 - categorical_accuracy: 0.7543 \n",
      "Epoch 9: saving model to model_init_4_2022-07-1209_53_17.910281/model-00009-0.57940-0.75433-2.73613-0.30000.h5\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "17/17 [==============================] - 395s 23s/step - loss: 0.5794 - categorical_accuracy: 0.7543 - val_loss: 2.7361 - val_categorical_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5446 - categorical_accuracy: 0.7889 \n",
      "Epoch 10: saving model to model_init_4_2022-07-1209_53_17.910281/model-00010-0.54456-0.78893-2.60728-0.38333.h5\n",
      "17/17 [==============================] - 392s 23s/step - loss: 0.5446 - categorical_accuracy: 0.7889 - val_loss: 2.6073 - val_categorical_accuracy: 0.3833 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4837 - categorical_accuracy: 0.8166 \n",
      "Epoch 11: saving model to model_init_4_2022-07-1209_53_17.910281/model-00011-0.48369-0.81661-2.09574-0.36667.h5\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "17/17 [==============================] - 396s 23s/step - loss: 0.4837 - categorical_accuracy: 0.8166 - val_loss: 2.0957 - val_categorical_accuracy: 0.3667 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3662 - categorical_accuracy: 0.8754 \n",
      "Epoch 12: saving model to model_init_4_2022-07-1209_53_17.910281/model-00012-0.36623-0.87543-0.89177-0.71667.h5\n",
      "17/17 [==============================] - 398s 23s/step - loss: 0.3662 - categorical_accuracy: 0.8754 - val_loss: 0.8918 - val_categorical_accuracy: 0.7167 - lr: 2.5000e-04\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3792 - categorical_accuracy: 0.8581 \n",
      "Epoch 13: saving model to model_init_4_2022-07-1209_53_17.910281/model-00013-0.37924-0.85813-0.82986-0.68333.h5\n",
      "17/17 [==============================] - 398s 23s/step - loss: 0.3792 - categorical_accuracy: 0.8581 - val_loss: 0.8299 - val_categorical_accuracy: 0.6833 - lr: 2.5000e-04\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3561 - categorical_accuracy: 0.8651 \n",
      "Epoch 14: saving model to model_init_4_2022-07-1209_53_17.910281/model-00014-0.35607-0.86505-0.58884-0.73333.h5\n",
      "17/17 [==============================] - 398s 23s/step - loss: 0.3561 - categorical_accuracy: 0.8651 - val_loss: 0.5888 - val_categorical_accuracy: 0.7333 - lr: 2.5000e-04\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2609 - categorical_accuracy: 0.9135 \n",
      "Epoch 15: saving model to model_init_4_2022-07-1209_53_17.910281/model-00015-0.26090-0.91349-0.84570-0.73333.h5\n",
      "17/17 [==============================] - 395s 23s/step - loss: 0.2609 - categorical_accuracy: 0.9135 - val_loss: 0.8457 - val_categorical_accuracy: 0.7333 - lr: 2.5000e-04\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2572 - categorical_accuracy: 0.8962 \n",
      "Epoch 16: saving model to model_init_4_2022-07-1209_53_17.910281/model-00016-0.25724-0.89619-1.29269-0.56667.h5\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "17/17 [==============================] - 393s 23s/step - loss: 0.2572 - categorical_accuracy: 0.8962 - val_loss: 1.2927 - val_categorical_accuracy: 0.5667 - lr: 2.5000e-04\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2362 - categorical_accuracy: 0.9204 \n",
      "Epoch 17: saving model to model_init_4_2022-07-1209_53_17.910281/model-00017-0.23621-0.92042-0.94656-0.60000.h5\n",
      "17/17 [==============================] - 394s 23s/step - loss: 0.2362 - categorical_accuracy: 0.9204 - val_loss: 0.9466 - val_categorical_accuracy: 0.6000 - lr: 1.2500e-04\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2705 - categorical_accuracy: 0.9100 \n",
      "Epoch 18: saving model to model_init_4_2022-07-1209_53_17.910281/model-00018-0.27046-0.91003-0.79353-0.75000.h5\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "17/17 [==============================] - 396s 23s/step - loss: 0.2705 - categorical_accuracy: 0.9100 - val_loss: 0.7935 - val_categorical_accuracy: 0.7500 - lr: 1.2500e-04\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.1575 - categorical_accuracy: 0.9723 \n",
      "Epoch 19: saving model to model_init_4_2022-07-1209_53_17.910281/model-00019-0.15751-0.97232-0.53882-0.75000.h5\n",
      "17/17 [==============================] - 396s 23s/step - loss: 0.1575 - categorical_accuracy: 0.9723 - val_loss: 0.5388 - val_categorical_accuracy: 0.7500 - lr: 6.2500e-05\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2057 - categorical_accuracy: 0.9343 \n",
      "Epoch 20: saving model to model_init_4_2022-07-1209_53_17.910281/model-00020-0.20571-0.93426-0.42235-0.81667.h5\n",
      "17/17 [==============================] - 398s 23s/step - loss: 0.2057 - categorical_accuracy: 0.9343 - val_loss: 0.4223 - val_categorical_accuracy: 0.8167 - lr: 6.2500e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc9181f9850>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.fit(train_generator, steps_per_epoch = steps_per_epoch, epochs = num_epochs, verbose = 1, \n",
    "                    callbacks = callbacks_list, validation_data = val_generator, \n",
    "                    validation_steps = validation_steps, class_weight = None, workers = 1, initial_epoch = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same inputs but changing the dropout values to counter overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 30\n",
    "y = 120\n",
    "z = 120\n",
    "\n",
    "batch_size = 40\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_shape = (30, 120, 120, 3)\n",
    "\n",
    "model_5 = Sequential()\n",
    "#first layer\n",
    "model_5.add(Conv3D(16, (3,3,3), padding='same', input_shape = Input_shape))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "#2nd layer\n",
    "model_5.add(Conv3D(32, (3, 3,3), padding = \"same\"))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "#3rd layer\n",
    "model_5.add(Conv3D(64, (3, 3,3), padding='same'))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "#4th layer\n",
    "model_5.add(Conv3D(128, (3, 3,3), padding = \"same\"))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(MaxPooling3D((2, 2,2), padding = \"same\"))\n",
    "\n",
    "model_5.add(Flatten())\n",
    "model_5.add(Dense(256))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Dropout(0.5))\n",
    "\n",
    "model_5.add(Dense(128))\n",
    "model_5.add(Activation(\"relu\"))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Dropout(0.5))\n",
    "\n",
    "model_5.add(Dense(5))\n",
    "model_5.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 30, 120, 120, 16)  1312      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 30, 120, 120, 16)  0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 30, 120, 120, 16)  64       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 15, 60, 60, 16)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 15, 60, 60, 32)    13856     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 15, 60, 60, 32)    0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 15, 60, 60, 32)   128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 8, 30, 30, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 8, 30, 30, 64)     55360     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 8, 30, 30, 64)     0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 30, 30, 64)    256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 4, 15, 15, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_3 (Conv3D)           (None, 4, 15, 15, 128)    221312    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4, 15, 15, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 15, 15, 128)   512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_3 (MaxPooling  (None, 2, 8, 8, 128)     0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               4194560   \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,522,437\n",
      "Trainable params: 4,521,189\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = tf.keras.optimizers.Adam(learning_rate = 0.001) #write your optimizer\n",
    "model_5.compile(optimizer = optimiser, loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "print(model_5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_5' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose = 1, save_best_only = False, save_weights_only = False, mode = 'auto', save_freq = 'epoch')\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 2, cooldown = 1, verbose = 1)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/train ; batch size = 40\n",
      "Epoch 1/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.8920 - categorical_accuracy: 0.3439 Source path =  Project_data/val ; batch size = 40\n",
      "\n",
      "Epoch 1: saving model to model_init_5_2022-07-1300_31_31.819012/model-00001-1.89204-0.34389-88.24358-0.23000.h5\n",
      "17/17 [==============================] - 779s 46s/step - loss: 1.8920 - categorical_accuracy: 0.3439 - val_loss: 88.2436 - val_categorical_accuracy: 0.2300 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.3886 - categorical_accuracy: 0.5294 \n",
      "Epoch 2: saving model to model_init_5_2022-07-1300_31_31.819012/model-00002-1.38860-0.52941-30.20901-0.28333.h5\n",
      "17/17 [==============================] - 461s 27s/step - loss: 1.3886 - categorical_accuracy: 0.5294 - val_loss: 30.2090 - val_categorical_accuracy: 0.2833 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.3347 - categorical_accuracy: 0.5038 \n",
      "Epoch 3: saving model to model_init_5_2022-07-1300_31_31.819012/model-00003-1.33471-0.50384-28.41864-0.23333.h5\n",
      "17/17 [==============================] - 463s 27s/step - loss: 1.3347 - categorical_accuracy: 0.5038 - val_loss: 28.4186 - val_categorical_accuracy: 0.2333 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2764 - categorical_accuracy: 0.5738 \n",
      "Epoch 4: saving model to model_init_5_2022-07-1300_31_31.819012/model-00004-1.27645-0.57382-6.02225-0.23333.h5\n",
      "17/17 [==============================] - 427s 25s/step - loss: 1.2764 - categorical_accuracy: 0.5738 - val_loss: 6.0223 - val_categorical_accuracy: 0.2333 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2231 - categorical_accuracy: 0.5697 \n",
      "Epoch 5: saving model to model_init_5_2022-07-1300_31_31.819012/model-00005-1.22313-0.56966-38.58215-0.21667.h5\n",
      "17/17 [==============================] - 385s 23s/step - loss: 1.2231 - categorical_accuracy: 0.5697 - val_loss: 38.5822 - val_categorical_accuracy: 0.2167 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2465 - categorical_accuracy: 0.5387 \n",
      "Epoch 6: saving model to model_init_5_2022-07-1300_31_31.819012/model-00006-1.24648-0.53870-20.06673-0.23333.h5\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "17/17 [==============================] - 386s 23s/step - loss: 1.2465 - categorical_accuracy: 0.5387 - val_loss: 20.0667 - val_categorical_accuracy: 0.2333 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2170 - categorical_accuracy: 0.5511 \n",
      "Epoch 7: saving model to model_init_5_2022-07-1300_31_31.819012/model-00007-1.21696-0.55108-9.52168-0.25000.h5\n",
      "17/17 [==============================] - 386s 23s/step - loss: 1.2170 - categorical_accuracy: 0.5511 - val_loss: 9.5217 - val_categorical_accuracy: 0.2500 - lr: 5.0000e-04\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0417 - categorical_accuracy: 0.5966 \n",
      "Epoch 8: saving model to model_init_5_2022-07-1300_31_31.819012/model-00008-1.04172-0.59661-10.92248-0.23333.h5\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "17/17 [==============================] - 353s 21s/step - loss: 1.0417 - categorical_accuracy: 0.5966 - val_loss: 10.9225 - val_categorical_accuracy: 0.2333 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.1107 - categorical_accuracy: 0.6263 \n",
      "Epoch 9: saving model to model_init_5_2022-07-1300_31_31.819012/model-00009-1.11066-0.62630-4.37500-0.28333.h5\n",
      "17/17 [==============================] - 347s 20s/step - loss: 1.1107 - categorical_accuracy: 0.6263 - val_loss: 4.3750 - val_categorical_accuracy: 0.2833 - lr: 2.5000e-04\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9570 - categorical_accuracy: 0.6505 \n",
      "Epoch 10: saving model to model_init_5_2022-07-1300_31_31.819012/model-00010-0.95702-0.65052-2.93366-0.20000.h5\n",
      "17/17 [==============================] - 345s 20s/step - loss: 0.9570 - categorical_accuracy: 0.6505 - val_loss: 2.9337 - val_categorical_accuracy: 0.2000 - lr: 2.5000e-04\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8675 - categorical_accuracy: 0.6505 \n",
      "Epoch 11: saving model to model_init_5_2022-07-1300_31_31.819012/model-00011-0.86755-0.65052-2.41756-0.26667.h5\n",
      "17/17 [==============================] - 341s 20s/step - loss: 0.8675 - categorical_accuracy: 0.6505 - val_loss: 2.4176 - val_categorical_accuracy: 0.2667 - lr: 2.5000e-04\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9424 - categorical_accuracy: 0.6298 \n",
      "Epoch 12: saving model to model_init_5_2022-07-1300_31_31.819012/model-00012-0.94243-0.62976-2.18807-0.28333.h5\n",
      "17/17 [==============================] - 339s 20s/step - loss: 0.9424 - categorical_accuracy: 0.6298 - val_loss: 2.1881 - val_categorical_accuracy: 0.2833 - lr: 2.5000e-04\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7875 - categorical_accuracy: 0.7128 \n",
      "Epoch 13: saving model to model_init_5_2022-07-1300_31_31.819012/model-00013-0.78751-0.71280-1.66455-0.36667.h5\n",
      "17/17 [==============================] - 344s 20s/step - loss: 0.7875 - categorical_accuracy: 0.7128 - val_loss: 1.6645 - val_categorical_accuracy: 0.3667 - lr: 2.5000e-04\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8015 - categorical_accuracy: 0.7024 \n",
      "Epoch 14: saving model to model_init_5_2022-07-1300_31_31.819012/model-00014-0.80154-0.70242-0.81803-0.70000.h5\n",
      "17/17 [==============================] - 346s 20s/step - loss: 0.8015 - categorical_accuracy: 0.7024 - val_loss: 0.8180 - val_categorical_accuracy: 0.7000 - lr: 2.5000e-04\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7309 - categorical_accuracy: 0.7266 \n",
      "Epoch 15: saving model to model_init_5_2022-07-1300_31_31.819012/model-00015-0.73093-0.72664-0.72751-0.75000.h5\n",
      "17/17 [==============================] - 345s 20s/step - loss: 0.7309 - categorical_accuracy: 0.7266 - val_loss: 0.7275 - val_categorical_accuracy: 0.7500 - lr: 2.5000e-04\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7419 - categorical_accuracy: 0.7232 \n",
      "Epoch 16: saving model to model_init_5_2022-07-1300_31_31.819012/model-00016-0.74187-0.72318-0.68640-0.70000.h5\n",
      "17/17 [==============================] - 340s 20s/step - loss: 0.7419 - categorical_accuracy: 0.7232 - val_loss: 0.6864 - val_categorical_accuracy: 0.7000 - lr: 2.5000e-04\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6648 - categorical_accuracy: 0.7578 \n",
      "Epoch 17: saving model to model_init_5_2022-07-1300_31_31.819012/model-00017-0.66482-0.75779-0.97274-0.58333.h5\n",
      "17/17 [==============================] - 343s 20s/step - loss: 0.6648 - categorical_accuracy: 0.7578 - val_loss: 0.9727 - val_categorical_accuracy: 0.5833 - lr: 2.5000e-04\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6951 - categorical_accuracy: 0.7093 \n",
      "Epoch 18: saving model to model_init_5_2022-07-1300_31_31.819012/model-00018-0.69514-0.70934-0.79671-0.65000.h5\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "17/17 [==============================] - 351s 21s/step - loss: 0.6951 - categorical_accuracy: 0.7093 - val_loss: 0.7967 - val_categorical_accuracy: 0.6500 - lr: 2.5000e-04\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6494 - categorical_accuracy: 0.7578 \n",
      "Epoch 19: saving model to model_init_5_2022-07-1300_31_31.819012/model-00019-0.64937-0.75779-0.53847-0.80000.h5\n",
      "17/17 [==============================] - 347s 20s/step - loss: 0.6494 - categorical_accuracy: 0.7578 - val_loss: 0.5385 - val_categorical_accuracy: 0.8000 - lr: 1.2500e-04\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6054 - categorical_accuracy: 0.7647 \n",
      "Epoch 20: saving model to model_init_5_2022-07-1300_31_31.819012/model-00020-0.60543-0.76471-0.73092-0.70000.h5\n",
      "17/17 [==============================] - 343s 20s/step - loss: 0.6054 - categorical_accuracy: 0.7647 - val_loss: 0.7309 - val_categorical_accuracy: 0.7000 - lr: 1.2500e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f919c563ee0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.fit(train_generator, steps_per_epoch = steps_per_epoch, epochs = num_epochs, verbose = 1, \n",
    "                    callbacks = callbacks_list, validation_data = val_generator, \n",
    "                    validation_steps = validation_steps, class_weight = None, workers = 1, initial_epoch = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model using GRU (CNN + RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the best model's parameters\n",
    "\n",
    "x = 30\n",
    "y = 120\n",
    "z = 120\n",
    "\n",
    "batch_size = 40\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, GRU,Dropout, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "model_gru = Sequential()\n",
    "Input_shape = (30, 120, 120, 3)\n",
    "\n",
    "#first layer\n",
    "model_gru.add(TimeDistributed(Conv2D(8, (3, 3),padding='same', activation='relu'),input_shape=Input_shape))\n",
    "model_gru.add(TimeDistributed(BatchNormalization()))\n",
    "model_gru.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "model_gru.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu')))\n",
    "model_gru.add(TimeDistributed(BatchNormalization()))\n",
    "model_gru.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "model_gru.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "model_gru.add(TimeDistributed(BatchNormalization()))\n",
    "model_gru.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "model_gru.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "model_gru.add(TimeDistributed(BatchNormalization()))\n",
    "model_gru.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "model_gru.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "model_gru.add(TimeDistributed(BatchNormalization()))\n",
    "model_gru.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "# Flatten layer \n",
    "model_gru.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_gru.add(GRU(64))\n",
    "model_gru.add(Dropout(0.5))\n",
    "\n",
    "# Dense layer \n",
    "model_gru.add(Dense(64, activation='relu'))\n",
    "model_gru.add(Dropout(0.5))\n",
    "\n",
    "# Softmax layer\n",
    "model_gru.add(Dense(5, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, 30, 120, 120, 8)  224       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 30, 120, 120, 8)  32        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 30, 60, 60, 8)    0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 30, 60, 60, 16)   1168      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 30, 60, 60, 16)   64        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 30, 30, 30, 16)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, 30, 30, 30, 32)   4640      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 30, 30, 30, 32)   128       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 30, 15, 15, 32)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, 30, 15, 15, 64)   18496     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_10 (TimeDi  (None, 30, 15, 15, 64)   256       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_11 (TimeDi  (None, 30, 7, 7, 64)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_12 (TimeDi  (None, 30, 7, 7, 128)    73856     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_13 (TimeDi  (None, 30, 7, 7, 128)    512       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_14 (TimeDi  (None, 30, 3, 3, 128)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_15 (TimeDi  (None, 30, 1152)         0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                233856    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 337,717\n",
      "Trainable params: 337,221\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = tf.keras.optimizers.Adam(learning_rate = 0.001) #write your optimizer\n",
    "model_gru.compile(optimizer = optimiser, loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "print(model_gru.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_gru_1' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_loss', verbose = 1, save_best_only = False, save_weights_only = False, mode = 'auto', save_freq = 'epoch')\n",
    "\n",
    "LR =ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 2, cooldown = 1, verbose = 1)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/train ; batch size = 40\n",
      "Epoch 1/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.7541 - categorical_accuracy: 0.2971Source path =  Project_data/val ; batch size = 40\n",
      "\n",
      "Epoch 1: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00001-1.75410-0.29713-2.38345-0.20000.h5\n",
      "17/17 [==============================] - 101s 6s/step - loss: 1.7541 - categorical_accuracy: 0.2971 - val_loss: 2.3834 - val_categorical_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.4940 - categorical_accuracy: 0.3734\n",
      "Epoch 2: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00002-1.49395-0.37340-2.33306-0.21667.h5\n",
      "17/17 [==============================] - 59s 4s/step - loss: 1.4940 - categorical_accuracy: 0.3734 - val_loss: 2.3331 - val_categorical_accuracy: 0.2167 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.4073 - categorical_accuracy: 0.4271\n",
      "Epoch 3: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00003-1.40733-0.42711-1.94130-0.23333.h5\n",
      "17/17 [==============================] - 59s 4s/step - loss: 1.4073 - categorical_accuracy: 0.4271 - val_loss: 1.9413 - val_categorical_accuracy: 0.2333 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.3424 - categorical_accuracy: 0.3844\n",
      "Epoch 4: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00004-1.34238-0.38440-2.10522-0.15000.h5\n",
      "17/17 [==============================] - 54s 3s/step - loss: 1.3424 - categorical_accuracy: 0.3844 - val_loss: 2.1052 - val_categorical_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2787 - categorical_accuracy: 0.4334\n",
      "Epoch 5: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00005-1.27871-0.43344-1.94254-0.26667.h5\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "17/17 [==============================] - 50s 3s/step - loss: 1.2787 - categorical_accuracy: 0.4334 - val_loss: 1.9425 - val_categorical_accuracy: 0.2667 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2627 - categorical_accuracy: 0.5077\n",
      "Epoch 6: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00006-1.26272-0.50774-1.78188-0.25000.h5\n",
      "17/17 [==============================] - 52s 3s/step - loss: 1.2627 - categorical_accuracy: 0.5077 - val_loss: 1.7819 - val_categorical_accuracy: 0.2500 - lr: 5.0000e-04\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2061 - categorical_accuracy: 0.4706\n",
      "Epoch 7: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00007-1.20610-0.47059-1.45502-0.36667.h5\n",
      "17/17 [==============================] - 50s 3s/step - loss: 1.2061 - categorical_accuracy: 0.4706 - val_loss: 1.4550 - val_categorical_accuracy: 0.3667 - lr: 5.0000e-04\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0574 - categorical_accuracy: 0.5729\n",
      "Epoch 8: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00008-1.05737-0.57288-1.33858-0.36667.h5\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.0574 - categorical_accuracy: 0.5729 - val_loss: 1.3386 - val_categorical_accuracy: 0.3667 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.1389 - categorical_accuracy: 0.5882\n",
      "Epoch 9: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00009-1.13893-0.58824-1.17988-0.56667.h5\n",
      "17/17 [==============================] - 46s 3s/step - loss: 1.1389 - categorical_accuracy: 0.5882 - val_loss: 1.1799 - val_categorical_accuracy: 0.5667 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0022 - categorical_accuracy: 0.5848\n",
      "Epoch 10: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00010-1.00223-0.58478-1.12550-0.51667.h5\n",
      "17/17 [==============================] - 46s 3s/step - loss: 1.0022 - categorical_accuracy: 0.5848 - val_loss: 1.1255 - val_categorical_accuracy: 0.5167 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9943 - categorical_accuracy: 0.5882\n",
      "Epoch 11: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00011-0.99429-0.58824-1.11558-0.56667.h5\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.9943 - categorical_accuracy: 0.5882 - val_loss: 1.1156 - val_categorical_accuracy: 0.5667 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.1142 - categorical_accuracy: 0.5156\n",
      "Epoch 12: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00012-1.11417-0.51557-1.20623-0.53333.h5\n",
      "17/17 [==============================] - 46s 3s/step - loss: 1.1142 - categorical_accuracy: 0.5156 - val_loss: 1.2062 - val_categorical_accuracy: 0.5333 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9758 - categorical_accuracy: 0.6055\n",
      "Epoch 13: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00013-0.97581-0.60554-1.01041-0.60000.h5\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.9758 - categorical_accuracy: 0.6055 - val_loss: 1.0104 - val_categorical_accuracy: 0.6000 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8966 - categorical_accuracy: 0.6505\n",
      "Epoch 14: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00014-0.89656-0.65052-0.95109-0.65000.h5\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.8966 - categorical_accuracy: 0.6505 - val_loss: 0.9511 - val_categorical_accuracy: 0.6500 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8922 - categorical_accuracy: 0.6574\n",
      "Epoch 15: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00015-0.89219-0.65744-1.01040-0.61667.h5\n",
      "17/17 [==============================] - 45s 3s/step - loss: 0.8922 - categorical_accuracy: 0.6574 - val_loss: 1.0104 - val_categorical_accuracy: 0.6167 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9264 - categorical_accuracy: 0.6021\n",
      "Epoch 16: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00016-0.92644-0.60208-1.13034-0.60000.h5\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.9264 - categorical_accuracy: 0.6021 - val_loss: 1.1303 - val_categorical_accuracy: 0.6000 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8222 - categorical_accuracy: 0.6609\n",
      "Epoch 17: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00017-0.82222-0.66090-1.01863-0.61667.h5\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.8222 - categorical_accuracy: 0.6609 - val_loss: 1.0186 - val_categorical_accuracy: 0.6167 - lr: 2.5000e-04\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7929 - categorical_accuracy: 0.7197\n",
      "Epoch 18: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00018-0.79290-0.71972-1.07113-0.65000.h5\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "17/17 [==============================] - 45s 3s/step - loss: 0.7929 - categorical_accuracy: 0.7197 - val_loss: 1.0711 - val_categorical_accuracy: 0.6500 - lr: 2.5000e-04\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7444 - categorical_accuracy: 0.6990\n",
      "Epoch 19: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00019-0.74444-0.69896-0.88310-0.63333.h5\n",
      "17/17 [==============================] - 45s 3s/step - loss: 0.7444 - categorical_accuracy: 0.6990 - val_loss: 0.8831 - val_categorical_accuracy: 0.6333 - lr: 1.2500e-04\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6989 - categorical_accuracy: 0.7197\n",
      "Epoch 20: saving model to model_init_gru_1_2022-07-1300_31_31.819012/model-00020-0.69889-0.71972-0.80678-0.75000.h5\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.6989 - categorical_accuracy: 0.7197 - val_loss: 0.8068 - val_categorical_accuracy: 0.7500 - lr: 1.2500e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f919fead7f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gru.fit(train_generator, steps_per_epoch = steps_per_epoch, epochs = num_epochs, verbose = 1, \n",
    "                    callbacks = callbacks_list, validation_data = val_generator, \n",
    "                    validation_steps = validation_steps, class_weight = None, workers = 1, initial_epoch = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
